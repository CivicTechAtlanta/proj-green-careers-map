# Back-end (Directus + Postgres + SQLite Prototype)

## Overview

This backend contains two approaches to working with job data:

1. **Dockerized CMS stack**

   - Postgres 16 + Directus CMS (via Docker Compose)
   - Accessible at **http://localhost:8055**
   - Stores persistent data in Docker volumes

2. **SQLite Prototype**
   - `create_database.py` builds a lightweight local SQLite database (`jobs.db`)
   - Seeds data from `jobs.csv`

---

## Prerequisites

- [Docker Desktop](https://www.docker.com/products/docker-desktop) (for Postgres + Directus)
- Docker Compose v2
- [Python 3.10+](https://www.python.org/downloads/) (for SQLite seed script)

---

## Option A: Run Directus + Postgres (Docker)

From the **backend** folder:

```sh
# Start services (detached)
docker compose up -d
```

Once healthy, open Directus at:

```
http://localhost:8055
```

**Default admin credentials (from docker-compose.yml):**

- Email: `admin@local.dev`
- Password: `password`

> ⚠️ These values are for local development only. Update before production.

### Common Commands

```sh
# View logs
docker compose logs -f

# Stop services
docker compose down

# Stop and remove data volumes (⚠️ wipes DB/uploads)
docker compose down -v

# Check service health
docker compose ps
```

---

## Option B: Run SQLite Prototype (Python)

If you just want to generate a small database from the CSV:

```sh
cd backend
python create_database.py
```

This will:

- Read `jobs.csv`
- Create `jobs.db` in the backend folder
- Insert all jobs into a `jobs` table

### Schema

```sql
CREATE TABLE jobs (
    id INTEGER PRIMARY KEY,
    category TEXT,
    job_name TEXT,
    job_description TEXT,
    skill_requirements TEXT,
    education_requirements TEXT,
    experience_requirements TEXT,
    base_hourly_rate REAL,
    max_hourly_rate REAL,
    base_annual_salary INTEGER,
    max_annual_salary INTEGER
);
```

### Verifying Data

```sh
sqlite3 jobs.db
sqlite> .tables
sqlite> SELECT job_name, base_annual_salary FROM jobs LIMIT 5;
```

---

## File Reference

- **docker-compose.yml** — spins up Postgres + Directus services with volumes.
- **create_database.py** — builds `jobs.db` (SQLite) from `jobs.csv`.
- **jobs.csv** — job data seed file.
- **jobs.db** — generated by running `create_database.py`.

---

## Troubleshooting

- **Directus not available on 8055**

  - `docker compose ps` to check running services
  - `docker compose logs -f directus`

- **Postgres healthcheck failing**

  - Ensure credentials match between Postgres + Directus in `docker-compose.yml`

- **SQLite script errors**
  - Ensure `jobs.csv` is in the same folder as `create_database.py`
  - Confirm you’re running Python 3.10+
